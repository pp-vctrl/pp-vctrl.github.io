<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="VCtrl is a unified framework for controllable video generation that enables precise spatiotemporal control by integrating diverse user-specified control signalsâ€”such as Canny edges, human keypoints, and segmentation masks.">
  <meta property="og:title" content="VCtrl: Enabling Versatile Controls for Video Diffusion Models"/>
  <meta property="og:description" content="VCtrl is a controllable video generation model that uses an auxiliary condition encoder to transform a text-to-video generation model into a custom video generator, without retraining of the original generator."/>
  <meta property="og:url" content="https:/pp-vctrl.github.io"/>
  <meta property="og:image" content="static/image/model.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="620"/>


  <meta name="twitter:title" content="VCtrl: Enabling Versatile Controls for Video Diffusion Models">
  <meta name="twitter:description" content="VCtrl a unified framework for controllable video generation that enables precise spatiotemporal control by integrating diverse user-specified control signalsâ€”such as Canny edges, human keypoints, and segmentation masks">
  <meta name="twitter:image" content="static/images/twitte_model.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Video diffusion models, controllable video generation, image-to-video, text-to-video">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>VCtrl: Enabling Versatile Controls for Video Diffusion Models  </title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" type="image/png" href="static/images/image.jpg">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Enabling Versatile Controls for Video Diffusion Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
             <span class="author-block">
               Xu Zhang</a><sup>1</sup>,
              </span>
              <span class="author-block">
               Hao Zhou</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Haoming Qin</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                Xiaobin Lu</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                Jiaxing Yan<sup>1</sup>,
              </span>
              <span class="author-block">
                Guanzhong Wang<sup>1</sup>,
              </span>
              <span class="author-block">
               Zeyu Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Yi Liu</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors" style="text-align: center;">
              <span class="author-block"><sup>1</sup>PaddlePaddle Team, Baidu Inc.</span>
              <span class="author-block"><sup>2</sup>Xiamen University</span>
              <span class="author-block"><sup>3</sup>Sun Yat-sen University</span>
            </div>
            
            <style>
              .publication-authors {
                display: flex;
                justify-content: center; /* å†…å®¹å±…ä¸­ */
                gap: 20px;
              }
              .author-block {
                white-space: nowrap;
              }
            </style>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/ppvctrl" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <!-- HuggingFace link -->
            <span class="link-block">
              <a href="https://huggingface.co/PaddleMIX" 
                 target="_blank"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">ðŸ¤—</span>
                <span>Models</span>
              </a>
            </span>
            
            <!-- AI studio link
            <span class="link-block">
              <a href="https://aistudio.baidu.com/projectdetail/8763487?searchKeyword=PP-VCtrl&searchTab=PROJECT" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span>Project</span>
            </a>
          </span> -->

            


            <!-- ArXiv abstract Link -->
            <!-- <span class="link-block">
              <a href="https://arxiv.org/abs/2302.01329" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>




<!-- <h1 style="text-align: center; font-size: 18px; margin-bottom: 20px;">
  We propose PP-Vctrl, a controllable video generation model that uses an auxiliary condition encoder to transform a text-to-video or image-to-video generation model into a custom video generator, without retraining of the original generator.
</h1> -->

<h2 class="title is-3" style="text-align: center; margin-top: 20px;">DEMOS SHOW</h2>

<!-- Canny Video Generation carousel -->
<section class="hero teaser">
      <div class="hero-body ">
    <div class="container is-max-desktop">
      
    <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-video1">
          <video poster="" id="header-video1" autoplay controls muted loop height="100%">
            <source src="static/videos/canny_longvideo_case1_hevc.mp4"
            type="video/mp4">
          </video>
        <h2 class="subtitle has-text-centered",style="font-weight: bold">
          " VCtrl-I2V-Canny can effortlessly assist creators in achieving style transfer from video to artwork by leveraging the video's edge features as control conditions."
        </h2>
        </div>

        <div class="item item-video2">
          <video poster="" id="header-video2" autoplay controls muted loop height="100%">
            <source src="static/videos/canny_longvideo_case2_hevc.mp4"
            type="video/mp4">
          </video>
        <h2 class="subtitle has-text-centered">
          "VCtrl-I2V-Canny can effortlessly assist creators in achieving style transfer from anime-style videos to real-world videos by leveraging the video's edge features as control conditions."
        </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End-->

<!--  Mask Video Generation carousel -->
<section class="hero teaser">
      <div class="hero-body ">
    <div class="container is-max-desktop">
      
    <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-video1">
          <video poster="" id="header-video1" autoplay controls muted loop height="100%">
            <source src="static/videos/mask_longvideo_case1_hevc.mp4"
            type="video/mp4">
          </video>
        <h2 class="subtitle has-text-centered",style="font-weight: bold">
          " VCtrl-I2V-Mask allows creators to easily perform diverse video editing tasks by selecting the specific content to be edited, enabling efficient customization."
        </h2>
        </div>

        <div class="item item-video2">
          <video poster="" id="header-video2" autoplay controls muted loop height="100%">
            <source src="static/videos/mask_longvideo_case2_hevc.mp4"
            type="video/mp4">
          </video>
        <h2 class="subtitle has-text-centered">
          " VCtrl-I2V-Mask allows creators to easily perform diverse video editing tasks by selecting the specific content to be edited, enabling efficient customization."
        </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End-->


<!--  Pose Video Generation carousel -->
<section class="hero teaser">
  <div class="hero-body ">
<div class="container is-max-desktop">
  
<div id="results-carousel" class="carousel results-carousel">
  <div class="item item-video1">
    <video poster="" id="header-video1" autoplay controls muted loop height="100%">
        <source src="static/videos/pose_case_10_hevc.mp4"
        type="video/mp4">
      </video>
  <h2 class="subtitle has-text-centered",style="font-weight: bold">
    "VCtrl-I2V-Pose enables creators to effortlessly achieve customized generation of character motion videos by extracting pose conditions."
  </h2>
  </div>
    
    <div class="item item-video1">
      <video poster="" id="header-video1" autoplay controls muted loop height="100%">
        <source src="static/videos/pose_case_11_hevc.mp4"
        type="video/mp4">
      </video>
    <h2 class="subtitle has-text-centered",style="font-weight: bold">
      "VCtrl-I2V-Pose enables creators to effortlessly achieve customized generation of character motion videos by extracting pose conditions."
    </h2>
    </div>
  </div>
</div>
</div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite substantial progress in text-to-video generation, achieving precise and flexible control over fine-grained spatiotemporal attributes remains a significant unresolved challenge in video generation research. To address these limitations, we introduce VCtrl (also termed PP-VCtrl), a novel framework designed to enable fine-grained control over pre-trained video diffusion models in a unified manner. VCtrl integrates diverse user-specified control signals-such as Canny edges, segmentation masks, and human keypoints-into pretrained video diffusion models via a generalizable conditional module capable of uniformly encoding multiple types of auxiliary signals without modifying the underlying generator. Additionally, we design a unified control signal encoding pipeline and a sparse residual connection mechanism to efficiently incorporate control representations. Comprehensive experiments and human evaluations demonstrate that VCtrl effectively enhances controllability and generation quality.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- How does it works ? -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">How does VCtrl works?</h2>
        <div class="content has-text-justified">
          <ul>
            <li><strong>We propose a Unified Control Signal Encoding pipeline.</strong> It transforms diverse video-based control signals into a unified latent representation, incorporating adaptive masks to enhance cross-condition adaptability.</li>
            <li><strong>We introduce VCtrl, a lightweight auxiliary control module.</strong> This Transformer-based module efficiently encodes abstract conditioning signals into residual representations, enabling precise and fine-grained control over the base model's internal representations.</li>
            <li><strong>We propose a Sparse Residual Connection Mechanism.</strong> This approach integrates residual representations from VCtrl into pre-trained models, effectively balancing control accuracy and computational efficiency.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- How dose VCtrl works ? -->

<!-- Paper Method -->
<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3" style="text-align: center;">Method Overview</h2> -->
        <div class="content has-text-justified">
          
          <center>
          <img src="static/images/model.jpg" alt="PP-VCtrl Video-Image Finetuning" class="center-image blend-img-background"/>
          </center>
          <div class="level-set has-text-justified">
            <p>
            <strong>Overview architecture of VCtrl</strong>. A control signal (e.g., Canny edges, semantic masks, or pose keypoints) is first encoded by the
              control encoder. The resulting representation is then additively combined with latent and incorporated into the Video Diffusion Model via
              the proposed VCtrl module, which leverages a sparse residual connection mechanism. After several iterative denoising steps, the refined
              latent is decoded by a pretrained VAE to produce the final video.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Paper Method -->
<!-- <h2 class="title is-3" style="text-align: center; margin-bottom: -1rem;">Comparisons with Other Methods</h2> -->


    <!-- å…±åŒçš„æ ‡é¢˜ -->
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container has-text-centered">
              <h2 class="title is-3" style="text-align: center; margin-bottom: -10rem;">Comparisons with Other Methods</h2>
            </div>
        </div>
    </section>

    <!-- Canny-to-Video -->
    <section class="section hero is-small ">
        <div class="hero-body">
            <div class="container is-max-desktop">
              <h2 class="title is-4" style="text-align: center; margin-bottom: 1.0rem;">Canny-to-Video</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/canny_comparison_case2_hevc.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/canny_comparison_case1_hevc.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Mask-to-Video -->
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
              <h2 class="title is-4" style="text-align: center; margin-bottom: 0.8rem;">Mask-to-Video</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/mask_comparison_case1_hevc1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/mask_comparison_case2_hevc2.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Pose-to-Video --> 
    <section class="hero is-small ">
        <div class="hero-body">
            <div class="container is-max-desktop">
              <h2 class="title is-4" style="text-align: center; margin-bottom: -1.6rem;">Pose-to-Video</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/pose_comparison_case1_hevc_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="header-video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/pose_comparison_case2_hevc_2.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>
</body>


<!-- Comparisons Quantitive-->
<section class="hero is-small">
  <div class="hero-body" style="text-align: center;">
    <h2 class="title is-4" style="text-align: center; margin-bottom: 2.0rem;">Quantitative Results</h2>
    <div class="container is-max-desktop">
    <p class="subtitle" style="text-align: left;">
      We present a comprehensive quantitative evaluation of our methods against existing representative approaches across three video generation tasks. For each task, we select suitable benchmarks and both established and newly proposed metrics to ensure a thorough comparison. Here are the quantitative results.
    </p>
    <div class="item item-image1">
      <img src="static/images/eval_1.png" alt="Canny Comparison Case 2" style="width: 100%; display: block; margin: 0 auto;">
  </div>
</section>


<!-- Canny v2v -->
<section class="section hero is-small is-light" style="padding: 1rem 0; margin-bottom: 0">
  <h2 class="title is-3" style="text-align: center">Diversity of Generated Video</h2>
    <div class="hero-body" style="padding: 0.5rem">
      <div class="container  is-max-desktop">

        <p class="subtitle" style="text-align: left;">
          Our method demonstrates strong generalizability by generating diverse video outputs from the same control signals, achieved through altering the initial reference frame. This capability underscores the flexibility and scalability of the proposed framework. Here are the various generated videos.
        </p>

        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/canny_case1_hevc.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/canny_case2_hevc.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <!-- Mask v2v -->
  <section class="section hero is-small is-light" style="padding: 1rem 0; margin: 0">
    <div class="hero-body" style="padding: 0.5rem">
      <div class="container  is-max-desktop">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/mask_case1_hevc.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/mask_case2_hevc.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <!-- Pose v2v -->
  <section class="section hero is-small is-light" style="padding: 1rem 0; margin-top: 0">
    <div class="hero-body" style="padding: 0.5rem">
      <div class="container  is-max-desktop">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/pose_case1.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="header-video1" autoplay controls muted loop height="100%">
              <source src="static/videos/pose_case2.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
<!-- End Pose v2v -->

<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/xcvnHhfDSGM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{molad2023dreamix,
  title={Enabling Versatile Controls for Video Diffusion Models},
  author={Xu Zhang and Hao Zhou and Haoming Qin and Xiaobin Lu and Jiaxing Yan and Guanzhong Wang and Zeyu Chen and Yi Liu},
  journal={arXiv preprint arXiv:2503.16983},
  year={2025},
}</code></pre>
  </div>
</section>
<!-- End BibTex citation -->

<!-- Acknowledgements
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
  We thank Ely Sarig for creating the video, Jay Tenenbaum for the video narration, Amir Hertz for the implementation of our eval baseline, Daniel Cohen-Or, Assaf Zomet, Eyal Segalis, Matan Kalman and Emily Denton for their valuable inputs that helped improve this work.
  </div>
</section> -->
<!--End Acknowledgements -->
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Dreamix
https://dreamix-video-editing.github.io -->
<!-- <script type="text/javascript">
var sc_project=12843789; 
var sc_invisible=1; 
var sc_security="e9c3bf5f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12843789/0/e9c3bf5f/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript> -->

<!-- End of Statcounter Code -->

</body>
</html>
